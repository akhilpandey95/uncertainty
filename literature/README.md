# Literature on uncertainity quantification
Summaries for the research papers and index highlighting meta information about the concept of uncertainty quantification in general.

## Directory Structure
- `summary/` - Summaries of the papers reviewed.
- `media/` - notes, diagrams, presentations related to the literature.

## References

[1]Y. Zhang, S. Pal, M. Coates, and D. Üstebay, “Bayesian graph convolutional neural networks for semi-supervised classification,” arXiv:1811.11103 [cs, stat], Nov. 2018, Accessed: May 28, 2020. [Online]. Available: http://arxiv.org/abs/1811.11103.

[2]S. Pal, F. Regol, and M. Coates, “Bayesian Graph Convolutional Neural Networks using Node Copying,” arXiv:1911.04965 [cs, stat], Nov. 2019, Accessed: May 28, 2020. [Online]. Available: http://arxiv.org/abs/1911.04965.

[3]S. Pal, F. Regol, and M. Coates, “Bayesian Graph Convolutional Neural Networks Using Non-Parametric Graph Learning,” arXiv:1910.12132 [cs, stat], Oct. 2019, Accessed: May 28, 2020. [Online]. Available: http://arxiv.org/abs/1910.12132.

[4]“Pal et al. - 2019 - Bayesian Graph Convolutional Neural Networks Using.pdf.” Accessed: May 28, 2020. [Online]. Available: https://arxiv.org/pdf/1910.12132.pdf.

[5]R. Pop and P. Fulop, “Deep Ensemble Bayesian Active Learning : Addressing the Mode Collapse issue in Monte Carlo dropout via Ensembles,” arXiv:1811.03897 [cs, stat], Nov. 2018, Accessed: May 28, 2020. [Online]. Available: http://arxiv.org/abs/1811.03897.

[6]“Comment: ICLR under review.” .

[7]“Pop and Fulop - 2018 - Deep Ensemble Bayesian Active Learning  Addressin.pdf.” Accessed: May 28, 2020. [Online]. Available: https://arxiv.org/pdf/1811.03897.pdf.

[8]S. Fort, H. Hu, and B. Lakshminarayanan, “Deep Ensembles: A Loss Landscape Perspective,” arXiv:1912.02757 [cs, stat], Dec. 2019, Accessed: May 28, 2020. [Online]. Available: http://arxiv.org/abs/1912.02757.

[9]“Fort et al. - 2019 - Deep Ensembles A Loss Landscape Perspective.pdf.” Accessed: May 28, 2020. [Online]. Available: https://arxiv.org/pdf/1912.02757.pdf.

[10]I. Osband, C. Blundell, A. Pritzel, and B. V. Roy, “Deep Exploration via Bootstrapped DQN,” p. 9.

[11]Y. Gal and Z. Ghahramani, “Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning,” arXiv:1506.02142 [cs, stat], Oct. 2016, Accessed: May 28, 2020. [Online]. Available: http://arxiv.org/abs/1506.02142.

[12]A. Carr and D. Wingate, “Graph Neural Processes: Towards Bayesian Graph Neural Networks,” arXiv:1902.10042 [cs, stat], Oct. 2019, Accessed: May 28, 2020. [Online]. Available: http://arxiv.org/abs/1902.10042.

[13]“Carr and Wingate - 2019 - Graph Neural Processes Towards Bayesian Graph Neu.pdf.” Accessed: May 28, 2020. [Online]. Available: https://arxiv.org/pdf/1902.10042.pdf.

[14]N. Wycoff, P. Balaprakash, and F. Xia, “Neuromorphic Acceleration for Approximate Bayesian Inference on Neural Networks via Permanent Dropout,” arXiv:1904.12904 [cs, stat], Apr. 2019, Accessed: May 26, 2020. [Online]. Available: http://arxiv.org/abs/1904.12904.

[15]S. Hu, N. Pezzotti, D. Mavroeidis, and M. Welling, “Simple and Accurate Uncertainty Quantification from Bias-Variance Decomposition,” arXiv:2002.05582 [cs, stat], Feb. 2020, Accessed: May 26, 2020. [Online]. Available: http://arxiv.org/abs/2002.05582.

[16]B. Lakshminarayanan, A. Pritzel, and C. Blundell, “Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles,” arXiv:1612.01474 [cs, stat], Nov. 2017, Accessed: May 28, 2020. [Online]. Available: http://arxiv.org/abs/1612.01474.

[17]D. M. Blei, A. Kucukelbir, and J. D. McAuliffe, “Variational Inference: A Review for Statisticians,” Journal of the American Statistical Association, vol. 112, no. 518, pp. 859–877, Apr. 2017, doi: 10.1080/01621459.2017.1285773.

[18]“Blei et al. - 2017 - Variational Inference A Review for Statisticians.pdf.” Accessed: May 28, 2020. [Online]. Available: https://arxiv.org/pdf/1601.00670.pdf.


## Author
[Akhil Pandey](https://github.com/akhilpandey95)


